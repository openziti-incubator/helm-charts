<!-- README.md generated by helm-docs from README.md.gotmpl -->
{{ template "chart.header" . }}
{{ template "chart.deprecationWarning" . }}

{{ template "chart.badgesSection" . }}

{{ template "chart.description" . }}

{{ template "chart.homepageLine" . }}

{{ template "chart.maintainersSection" . }}

{{ template "chart.sourcesSection" . }}

{{ template "chart.requirementsSection" . }}

## Overview

You may use this chart to reach services node-wide via your Ziti network via DNS. For example, if you create a repository or container registry Ziti service, and your cluster has no internet access, you can reach those repositories or container registries via Ziti services.
**NOTE: This approach has an unsolved problem.** CoreDNS answers Ziti DNS by forwarding the query to the tunneler pod on it's own node. The response is the Ziti intercept IP address on the controller node where CoreDNS is running, not necessarily the node where the pod is running that sent the original DNS query.
All nodes have the same Ziti Identity and so they obtain the same list of services from the Ziti controller and in most cases the mapping of Ziti addresses is identical, but there is no guarantee this is the case because Ziti intercept IP addresses are always picked on the node, not globally unique for the Ziti network.
This means the daemonset works when there's only one K8s node or only one Ziti service, and the risk of an incorrect IP intercept increases from there. This is a DNS related problem, so it does not affect Ziti services that don't employ DNS.
If it's possible, one solution would be to configure K8s so that every node runs CoreDNS and all pods only query DNS on their own node.

## How this Chart Works

This chart deploys a pod running `ziti-edge-tunnel`, [the OpenZiti Linux tunneler](https://docs.openziti.io/docs/reference/tunnelers/linux/), in transparent proxy mode with DNS nameserver. The chart uses container image `docker.io/openziti/ziti-edge-tunnel` which runs `ziti-edge-tunnel run`.

## Installation

```console
helm repo add openziti https://docs.openziti.io/helm-charts/
```

After adding the charts repo to Helm then you may enroll the identity and install the chart. You must supply a Ziti identity JSON file when you install the chart.

```console
ziti edge enroll --jwt /tmp/k8s-tunneler.jwt --out /tmp/k8s-tunneler.json
helm install ziti-run-node openziti/ziti-tunnel --set-file zitiIdentity=/tmp/k8s-tunneler-03.json
```

### Installation using a existing / pre-created secret

Alternatively when you want to use a existing / pre-created secret (i.e. you have sealed-secrets enabled in your setup), you could refer to an existing secret with the ziti identity to use.

This sample shows you how to create the secret:

```console
kubectl create secret generic k8s-tunneler-identity --from-file=persisted-identity=k8s-tunneler.json
```

When you deploy the helm chart refer to the existing secret:

```console
helm install ziti-run-node openziti/ziti-tunnel --set secret.existingSecretName=k8s-tunneler-identity
```

When you don't want to use the default key name `persisted-identity` you can define your own name by adding `--set secret.keyName=myKeyName`.

### Configure CoreDNS

If you want to resolve your Ziti domain inside the pods, you need to customize CoreDNS. See [Official docs](https://openziti.io/docs/guides/kubernetes/workload-tunneling/kubernetes-daemonset/).

Customize CoreDNS configuration,

```console
kubectl -n kube-system apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns-custom
  namespace: kube-system
data:
  ziti.server: |
    your.ziti.domain {
      forward . 100.64.0.2
    }
EOF
```

Reload CoreDNS config,

```console
kubectl rollout restart -n kube-system deployment/coredns
```


## Values Reference

{{ template "chart.valuesTable" . }}

```console
helm upgrade {release} {source dir}
```

<!-- README.md generated by helm-docs from README.md.gotmpl -->
